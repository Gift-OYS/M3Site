{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60fc5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%set_env TOKENIZERS_PARALLELISM=false\n",
    "from predict import model_predict\n",
    "\n",
    "model = 'M3Site-ESM3-abs'   # If you want to use ESM3 as PLM, you may need to have the access\n",
    "pdb_file = '/path/to/your/pdb_file.pdb'\n",
    "function = 'Unknown'\n",
    "\n",
    "\n",
    "# Option 1: Use the pretrained model from Hugging Face\n",
    "result = model_predict(model, pdb_file, function,\n",
    "                        device='cuda:0'\n",
    "                    )\n",
    "\n",
    "# Option 2: Use the pretrained model from local path\n",
    "plm_path = '/path/to/esm3-sm-open-v1'\n",
    "blm_path = '/path/to/BiomedNLP-BiomedBERT-base-uncased-abstract'\n",
    "result = model_predict(model, pdb_file, function,\n",
    "                        plm_path, blm_path, \n",
    "                        device='cuda:0'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "568fa31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.load('/home/v-songouyang/codes/M3Site/data/3_abs/A8ALX7.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fd49f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[239, 1], edge_index=[2, 1241], edge_attr=[1241, 1], pos=[239, 3], esm_rep=[239, 1536], prop=[239, 62], func=[768])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04d1fdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "train1 = pd.read_csv('/home/v-songouyang/codes/M3Site/data/splits/train/train_0.1.tsv', sep='\\t')\n",
    "train3 = pd.read_csv('/home/v-songouyang/codes/M3Site/data/splits/train/train_0.3.tsv', sep='\\t')\n",
    "train5 = pd.read_csv('/home/v-songouyang/codes/M3Site/data/splits/train/train_0.5.tsv', sep='\\t')\n",
    "train7 = pd.read_csv('/home/v-songouyang/codes/M3Site/data/splits/train/train_0.7.tsv', sep='\\t')\n",
    "train9 = pd.read_csv('/home/v-songouyang/codes/M3Site/data/splits/train/train_0.9.tsv', sep='\\t')\n",
    "valid1 = pd.read_csv('/home/v-songouyang/codes/M3Site/data/splits/valid/valid_0.1.tsv', sep='\\t')\n",
    "valid3 = pd.read_csv('/home/v-songouyang/codes/M3Site/data/splits/valid/valid_0.3.tsv', sep='\\t')\n",
    "valid5 = pd.read_csv('/home/v-songouyang/codes/M3Site/data/splits/valid/valid_0.5.tsv', sep='\\t')\n",
    "valid7 = pd.read_csv('/home/v-songouyang/codes/M3Site/data/splits/valid/valid_0.7.tsv', sep='\\t')\n",
    "valid9 = pd.read_csv('/home/v-songouyang/codes/M3Site/data/splits/valid/valid_0.9.tsv', sep='\\t')\n",
    "test1 = pd.read_csv('/home/v-songouyang/codes/M3Site/data/splits/test/test_0.1.tsv', sep='\\t')\n",
    "test3 = pd.read_csv('/home/v-songouyang/codes/M3Site/data/splits/test/test_0.3.tsv', sep='\\t')\n",
    "test5 = pd.read_csv('/home/v-songouyang/codes/M3Site/data/splits/test/test_0.5.tsv', sep='\\t')\n",
    "test7 = pd.read_csv('/home/v-songouyang/codes/M3Site/data/splits/test/test_0.7.tsv', sep='\\t')\n",
    "test9 = pd.read_csv('/home/v-songouyang/codes/M3Site/data/splits/test/test_0.9.tsv', sep='\\t')\n",
    "\n",
    "label = json.load(open('/home/v-songouyang/codes/M3Site/data/label.json', 'r'))\n",
    "\n",
    "pt_path = '/home/v-songouyang/codes/M3Site/data/3_abs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7ba014e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 294/6423 [00:00<00:04, 1480.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6423/6423 [00:03<00:00, 1841.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in train_0.1_new: 5613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7127/7127 [00:03<00:00, 1840.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in train_0.3_new: 6255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13332/13332 [00:07<00:00, 1852.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in train_0.5_new: 11724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20409/20409 [01:10<00:00, 290.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in train_0.7_new: 17848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22696/22696 [00:42<00:00, 534.32it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in train_0.9_new: 19988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 813/813 [00:00<00:00, 1080.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in valid_0.1_new: 726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 936/936 [00:00<00:00, 1791.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in valid_0.3_new: 805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1689/1689 [00:01<00:00, 1610.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in valid_0.5_new: 1385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2572/2572 [00:03<00:00, 816.32it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in valid_0.7_new: 2213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2835/2835 [00:04<00:00, 591.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in valid_0.9_new: 2464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 767/767 [00:00<00:00, 1699.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in test_0.1_new: 707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 871/871 [00:00<00:00, 1656.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in test_0.3_new: 766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1708/1708 [00:01<00:00, 1532.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in test_0.5_new: 1483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2488/2488 [00:02<00:00, 935.67it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in test_0.7_new: 2230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2778/2778 [00:02<00:00, 984.13it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in test_0.9_new: 2428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "to_drop_list = []\n",
    "for idx in tqdm(range(len(train1))):\n",
    "    entity = train1['Entry'].values[idx]\n",
    "    if entity not in label:\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    path = f'{pt_path}/{entity}.pt'\n",
    "    if not os.path.exists(path):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    data = torch.load(path)\n",
    "    if data.x.shape[0] != len(label[entity]):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "\n",
    "train1 = train1.drop(to_drop_list).reset_index(drop=True)\n",
    "train1.to_csv('/home/v-songouyang/codes/M3Site/data/splits/train/train_0.1_new.tsv', sep='\\t', index=False)\n",
    "print(f'Number of samples in train_0.1_new: {len(train1)}')\n",
    "\n",
    "to_drop_list = []\n",
    "for idx in tqdm(range(len(train3))):\n",
    "    entity = train3['Entry'].values[idx]\n",
    "    if entity not in label:\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    path = f'{pt_path}/{entity}.pt'\n",
    "    if not os.path.exists(path):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    data = torch.load(path)\n",
    "    if data.x.shape[0] != len(label[entity]):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "train3 = train3.drop(to_drop_list).reset_index(drop=True)\n",
    "train3.to_csv('/home/v-songouyang/codes/M3Site/data/splits/train/train_0.3_new.tsv', sep='\\t', index=False)\n",
    "print(f'Number of samples in train_0.3_new: {len(train3)}')\n",
    "\n",
    "to_drop_list = []\n",
    "for idx in tqdm(range(len(train5))):\n",
    "    entity = train5['Entry'].values[idx]\n",
    "    if entity not in label:\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    path = f'{pt_path}/{entity}.pt'\n",
    "    if not os.path.exists(path):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    data = torch.load(path)\n",
    "    if data.x.shape[0] != len(label[entity]):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "train5 = train5.drop(to_drop_list).reset_index(drop=True)\n",
    "train5.to_csv('/home/v-songouyang/codes/M3Site/data/splits/train/train_0.5_new.tsv', sep='\\t', index=False)\n",
    "print(f'Number of samples in train_0.5_new: {len(train5)}')\n",
    "\n",
    "to_drop_list = []\n",
    "for idx in tqdm(range(len(train7))):\n",
    "    entity = train7['Entry'].values[idx]\n",
    "    if entity not in label:\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    path = f'{pt_path}/{entity}.pt'\n",
    "    if not os.path.exists(path):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    data = torch.load(path)\n",
    "    if data.x.shape[0] != len(label[entity]):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "train7 = train7.drop(to_drop_list).reset_index(drop=True)\n",
    "train7.to_csv('/home/v-songouyang/codes/M3Site/data/splits/train/train_0.7_new.tsv', sep='\\t', index=False)\n",
    "print(f'Number of samples in train_0.7_new: {len(train7)}')\n",
    "\n",
    "to_drop_list = []\n",
    "for idx in tqdm(range(len(train9))):\n",
    "    entity = train9['Entry'].values[idx]\n",
    "    if entity not in label:\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    path = f'{pt_path}/{entity}.pt'\n",
    "    if not os.path.exists(path):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    data = torch.load(path)\n",
    "    if data.x.shape[0] != len(label[entity]):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "train9 = train9.drop(to_drop_list).reset_index(drop=True)\n",
    "train9.to_csv('/home/v-songouyang/codes/M3Site/data/splits/train/train_0.9_new.tsv', sep='\\t', index=False)\n",
    "print(f'Number of samples in train_0.9_new: {len(train9)}')\n",
    "\n",
    "to_drop_list = []\n",
    "for idx in tqdm(range(len(valid1))):\n",
    "    entity = valid1['Entry'].values[idx]\n",
    "    if entity not in label:\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    path = f'{pt_path}/{entity}.pt'\n",
    "    if not os.path.exists(path):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    data = torch.load(path)\n",
    "    if data.x.shape[0] != len(label[entity]):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "valid1 = valid1.drop(to_drop_list).reset_index(drop=True)\n",
    "valid1.to_csv('/home/v-songouyang/codes/M3Site/data/splits/valid/valid_0.1_new.tsv', sep='\\t', index=False)\n",
    "print(f'Number of samples in valid_0.1_new: {len(valid1)}')\n",
    "\n",
    "to_drop_list = []\n",
    "for idx in tqdm(range(len(valid3))):\n",
    "    entity = valid3['Entry'].values[idx]\n",
    "    if entity not in label:\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    path = f'{pt_path}/{entity}.pt'\n",
    "    if not os.path.exists(path):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    data = torch.load(path)\n",
    "    if data.x.shape[0] != len(label[entity]):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "valid3 = valid3.drop(to_drop_list).reset_index(drop=True)\n",
    "valid3.to_csv('/home/v-songouyang/codes/M3Site/data/splits/valid/valid_0.3_new.tsv', sep='\\t', index=False)\n",
    "print(f'Number of samples in valid_0.3_new: {len(valid3)}')\n",
    "\n",
    "to_drop_list = []\n",
    "for idx in tqdm(range(len(valid5))):\n",
    "    entity = valid5['Entry'].values[idx]\n",
    "    if entity not in label:\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    path = f'{pt_path}/{entity}.pt'\n",
    "    if not os.path.exists(path):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    data = torch.load(path)\n",
    "    if data.x.shape[0] != len(label[entity]):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "valid5 = valid5.drop(to_drop_list).reset_index(drop=True)\n",
    "valid5.to_csv('/home/v-songouyang/codes/M3Site/data/splits/valid/valid_0.5_new.tsv', sep='\\t', index=False)\n",
    "print(f'Number of samples in valid_0.5_new: {len(valid5)}')\n",
    "\n",
    "to_drop_list = []\n",
    "for idx in tqdm(range(len(valid7))):\n",
    "    entity = valid7['Entry'].values[idx]\n",
    "    if entity not in label:\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    path = f'{pt_path}/{entity}.pt'\n",
    "    if not os.path.exists(path):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    data = torch.load(path)\n",
    "    if data.x.shape[0] != len(label[entity]):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "valid7 = valid7.drop(to_drop_list).reset_index(drop=True)\n",
    "valid7.to_csv('/home/v-songouyang/codes/M3Site/data/splits/valid/valid_0.7_new.tsv', sep='\\t', index=False)\n",
    "print(f'Number of samples in valid_0.7_new: {len(valid7)}')\n",
    "\n",
    "to_drop_list = []\n",
    "for idx in tqdm(range(len(valid9))):\n",
    "    entity = valid9['Entry'].values[idx]\n",
    "    if entity not in label:\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    path = f'{pt_path}/{entity}.pt'\n",
    "    if not os.path.exists(path):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    data = torch.load(path)\n",
    "    if data.x.shape[0] != len(label[entity]):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "valid9 = valid9.drop(to_drop_list).reset_index(drop=True)\n",
    "valid9.to_csv('/home/v-songouyang/codes/M3Site/data/splits/valid/valid_0.9_new.tsv', sep='\\t', index=False)\n",
    "print(f'Number of samples in valid_0.9_new: {len(valid9)}')\n",
    "\n",
    "to_drop_list = []\n",
    "for idx in tqdm(range(len(test1))):\n",
    "    entity = test1['Entry'].values[idx]\n",
    "    if entity not in label:\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    path = f'{pt_path}/{entity}.pt'\n",
    "    if not os.path.exists(path):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    data = torch.load(path)\n",
    "    if data.x.shape[0] != len(label[entity]):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "test1 = test1.drop(to_drop_list).reset_index(drop=True)\n",
    "test1.to_csv('/home/v-songouyang/codes/M3Site/data/splits/test/test_0.1_new.tsv', sep='\\t', index=False)\n",
    "print(f'Number of samples in test_0.1_new: {len(test1)}')\n",
    "\n",
    "to_drop_list = []\n",
    "for idx in tqdm(range(len(test3))):\n",
    "    entity = test3['Entry'].values[idx]\n",
    "    if entity not in label:\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    path = f'{pt_path}/{entity}.pt'\n",
    "    if not os.path.exists(path):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    data = torch.load(path)\n",
    "    if data.x.shape[0] != len(label[entity]):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "test3 = test3.drop(to_drop_list).reset_index(drop=True)\n",
    "test3.to_csv('/home/v-songouyang/codes/M3Site/data/splits/test/test_0.3_new.tsv', sep='\\t', index=False)\n",
    "print(f'Number of samples in test_0.3_new: {len(test3)}')\n",
    "\n",
    "to_drop_list = []\n",
    "for idx in tqdm(range(len(test5))):\n",
    "    entity = test5['Entry'].values[idx]\n",
    "    if entity not in label:\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    path = f'{pt_path}/{entity}.pt'\n",
    "    if not os.path.exists(path):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    data = torch.load(path)\n",
    "    if data.x.shape[0] != len(label[entity]):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "test5 = test5.drop(to_drop_list).reset_index(drop=True)\n",
    "test5.to_csv('/home/v-songouyang/codes/M3Site/data/splits/test/test_0.5_new.tsv', sep='\\t', index=False)\n",
    "print(f'Number of samples in test_0.5_new: {len(test5)}')\n",
    "\n",
    "to_drop_list = []\n",
    "for idx in tqdm(range(len(test7))):\n",
    "    entity = test7['Entry'].values[idx]\n",
    "    if entity not in label:\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    path = f'{pt_path}/{entity}.pt'\n",
    "    if not os.path.exists(path):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    data = torch.load(path)\n",
    "    if data.x.shape[0] != len(label[entity]):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "test7 = test7.drop(to_drop_list).reset_index(drop=True)\n",
    "test7.to_csv('/home/v-songouyang/codes/M3Site/data/splits/test/test_0.7_new.tsv', sep='\\t', index=False)\n",
    "print(f'Number of samples in test_0.7_new: {len(test7)}')\n",
    "\n",
    "to_drop_list = []\n",
    "for idx in tqdm(range(len(test9))):\n",
    "    entity = test9['Entry'].values[idx]\n",
    "    if entity not in label:\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    path = f'{pt_path}/{entity}.pt'\n",
    "    if not os.path.exists(path):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "    data = torch.load(path)\n",
    "    if data.x.shape[0] != len(label[entity]):\n",
    "        to_drop_list.append(idx)\n",
    "        continue\n",
    "test9 = test9.drop(to_drop_list).reset_index(drop=True)\n",
    "test9.to_csv('/home/v-songouyang/codes/M3Site/data/splits/test/test_0.9_new.tsv', sep='\\t', index=False)\n",
    "print(f'Number of samples in test_0.9_new: {len(test9)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f56ccd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "810"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m3site",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
